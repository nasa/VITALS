{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Working with EMIT L2A Reflectance\n",
    "\n",
    "## Summary    \n",
    "\n",
    "This notebook will explain how to access Earth Surface Mineral Dust Source Investigation (EMIT) data programmatically using the [earthaccess Python library](https://github.com/nsidc/earthaccess). `earthaccess` is a useful Python library that facilitates finding and downloading or streaming data over HTTPS or s3. `earthaccess` searches NASA's Common Metadata Repository (CMR), a metadata system that catalogs Earth Science data and associated metadata records, then can be used to download granules or generate lists of granule search result URLs.  \n",
    "\n",
    "## Requirements  \n",
    "\n",
    "- A NASA [Earthdata Login](https://urs.earthdata.nasa.gov/) account is required.   \n",
    "\n",
    "## Learning Objectives  \n",
    "\n",
    "- How to find EMIT data using `earthaccess`\n",
    "- How to work with EMIT reflectance data\n",
    "- How to mask and quality filter EMIT reflectance data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Import the Python libraries we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import warnings\n",
    "# Some cells may generate warnings that we can ignore. Comment below lines to see.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import earthaccess\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import rasterio as rio\n",
    "import rioxarray as rxr\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "import geopandas as gp\n",
    "from shapely.geometry import Polygon\n",
    "from modules.emit_tools import emit_xarray, ortho_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we we are importing a local module for handling EMIT data called `emit_tools`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate  \n",
    "\n",
    "Earthdata Login credentials (i.e., username and password) are required to access NASA Earthdata data assets. We will use the `earthaccess` package to authenticate using our Earthdata Login credentials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login(persist=True)\n",
    "auth.refresh_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for EMIT Data  \n",
    "\n",
    "In this exercise, we want to find the EMIT L2 reflectance granules/scenes that intersect with our regions of interest (ROI) and for our specified date range. We can use a geojson or a shapefile file containing our ROI or pass the bounding box of the feature to the `earthaccess` `search_data()` function to identify granules/scenes that we are interested in. Here we are using a bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = (-105.301, 39.957, -105.178, 40.094)\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the **bbox** Python variable to the `bounding_box` argument and enter a start and end date, as a Python tuple, to the `temporal` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    short_name='EMITL2ARFL',\n",
    "    bounding_box=bbox,\n",
    "    temporal=('2023-06-01','2023-09-30'),\n",
    "    count=100\n",
    ")\n",
    "print(f\"Granules Found: {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `data_links()` convenience function to extract the data links for all of the granules. In this case there are multiple files associated with a single granule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_results_urls = [granule.data_links(access=\"external\") for granule in results]\n",
    "emit_results_urls[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine our list of lists into a single list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [url for urls in emit_results_urls for url in urls]\n",
    "url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with EMIT Data\n",
    "\n",
    "EMIT collections and their associated granules are archived and distributed from NASA's Earthdata Cloud. Because of this, data assets/files can be accessed in a variety of ways. Data distributed from Earthdata Cloud can be:\n",
    "\n",
    "**Downloaded** – This has been a supported option since the inception of NASA's DAACs. Users can use the data link(s) to download files to their local working environment. This method works in both cloud and non-cloud environments.\n",
    "\n",
    "**Streamed** – Streaming enables on-the-fly reading of remote files (i.e., files not saved locally). However, the accessed data must fit into the workspace’s memory. Streaming works in both cloud and non-cloud environments. Streaming data stored in the cloud without downloading is called **in-place access or direct S3 access**. this is only available when working in a cloud environment deployed in AWS us-west-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data  \n",
    "\n",
    "The `download()` function from `earthaccess` can be used to efficiently download the data links from a `earthaccess` search results. A list of URLs can also be passed to the function. The convenient part of using the `download()` function is that authentication is taken care of on behalf of the user.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download `earthaccess` search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earthaccess.download(results, local_path='../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download from URL list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#earthaccess.download(url_list, local_path='../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Data  \n",
    "\n",
    "Data in NASA Earthdata Cloud can be read into the workspace by streaming the data, that is, no download is required. Here we will assign a single URL for EMIT *reflectance* and for the *mask* layer from our **url_list** to read in and explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_rfl = url_list[3]\n",
    "emit_rfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_qa = url_list[5]\n",
    "emit_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pass our Earthdata Login credentials to stream data from NASA's Earthdata Cloud. We will use `get_fsspec_https_session()` function from `earthaccess` library to pass this information and allow us to access these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HTTPS Session using Earthdata Login Info\n",
    "fs = earthaccess.get_fsspec_https_session()\n",
    "\n",
    "# Use the session (i.e., fs) to connect to the file\n",
    "emit_fp = fs.open(emit_rfl)\n",
    "emit_qa_fp = fs.open(emit_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an authenticated connection to the data links. We can now start exploring these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening and Exploring EMIT Reflectance Data\n",
    "\n",
    "EMIT L2A Reflectance Data are distributed in a non-orthocorrected spatially raw NetCDF4 (.nc) format consisting of the data and its associated metadata. Inside the L2A Reflectance `.nc` file there are 3 groups. Groups can be thought of as containers to organize the data. \n",
    "\n",
    "1. The root group that can be considered the main dataset contains the reflectance data described by the downtrack, crosstrack, and bands dimensions.  \n",
    "2. The `sensor_band_parameters`  group containing the wavelength center and the full-width half maximum (FWHM) of each band.  \n",
    "3. The `location` group contains latitude and longitude values at the center of each pixel described by the crosstrack and downtrack dimensions, as well as a geometry lookup table (GLT) described by the ortho_x and ortho_y dimensions. The GLT is an orthorectified image (EPSG:4326) consisting of 2 layers containing downtrack and crosstrack indices. These index positions allow us to quickly project the raw data onto this geographic grid.\n",
    "\n",
    "To work with the EMIT data, we will use the `emit_tools` module. There are other ways to work with the data and a more thorough explanation of the `emit_tools` in the [EMIT-Data-Resources Repository](https://github.com/nasa/EMIT-Data-Resources).\n",
    "\n",
    "Open the example EMIT scene using the `emit_xarray` function. In this step we will use the `ortho=False` argument (default) read in the data in its source non-orthocorrected form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data to speed up future cells\n",
    "emit_ds = emit_xarray(emit_fp, ortho=False).load()\n",
    "emit_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the **wavelengths** coordinate variable is indexed, we can use `sel()` functions to filter for specific wavelength values from our EMIT datacube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_ds['reflectance'].sel(wavelengths=380, method='nearest').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the orientation of the plotted image. Remember this is not orthocorrected and thus is not north up. You may notice that EMIT radiance and reflectance scenes rows of missing data in some scenes. This is due to EMIT's on-board cloud filtering. Additionally, filtering can be applied using the **mask** layer (example later in this exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # This cell isn't needed - Just another capability to subset the streamed data before orthorectifying\n",
    "# # This is more efficient in terms of memory and slightly faster, but doesn't look as nice for the interactive explore cell\n",
    "# # Load polygon\n",
    "# shape = gp.read_file(\"../data/dangermond_boundary.geojson\")\n",
    "# # Subset and load\n",
    "# emit_ds = spatial_subset(emit_xarray(emit_fp), shape).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create an orthocorrected image of our data using the `ortho_xr()` function from the `emit_tools` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_ds = ortho_xr(emit_ds)\n",
    "emit_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_ds['reflectance'].sel(wavelengths=380, method='nearest').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a orthorectified image that is north up! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `good_wavelengths` flag from the `sensor_band_parameters` group, we can mask out bands where water absorption features were assigned a value of -0.01 reflectance. Typically data around 1320-1440 nm and 1770-1970 nm is noisy due to the moisture present in the atmosphere; therefore, these spectral regions offer little information about targets and can be excluded from calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_ds['reflectance'].data[:,:,emit_ds['good_wavelengths'].data==0] = np.nan\n",
    "emit_ds['reflectance'].data[emit_ds['reflectance'].data == -9999] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot a Spectra  \n",
    "\n",
    "We will now plot the spectra of an individual pixel closest to a specified latitude and longitude we want using the `sel` function from `xarray`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scene_center = emit_ds.latitude.values[int(len(emit_ds.latitude)/2)],emit_ds.longitude.values[int(len(emit_ds.longitude)/2)]\n",
    "scene_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#point = emit_ds.sel(latitude=scene_center[0],longitude=scene_center[1], method='nearest')\n",
    "point = emit_ds.sel(latitude=40.2, longitude=-105.6, method='nearest')\n",
    "\n",
    "point.hvplot.line(y='reflectance', \n",
    "                  x='wavelengths', \n",
    "                  color='black').opts(title=f'Latitude = {point.latitude.values.round(3)}, Longitude = {point.longitude.values.round(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot individual bands spatially by selecting a wavelength, then plotting. Select the band with a wavelengths of 850 nm and plot it using ESRI imagery as a basemap to get a better understanding of where the scene was acquired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_layer = emit_ds.sel(wavelengths=850,method='nearest')\n",
    "\n",
    "emit_layer.hvplot.image(cmap='viridis',\n",
    "                        geo=True, \n",
    "                        tiles='ESRI', \n",
    "                        crs='EPSG:4326', \n",
    "                        frame_width=720,\n",
    "                        frame_height=405, \n",
    "                        alpha=0.7, \n",
    "                        fontscale=2).opts(title=f\"{emit_layer.wavelengths:.3f} {emit_layer.wavelengths.units}\", xlabel='Longitude',ylabel='Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying Quality Masks to EMIT Data\n",
    "\n",
    "The EMIT L2A Mask file contains some bands that are direct masks (Cloud, Dilated, Cirrus, Water, Spacecraft), and some (AOD550 and H2O (g cm-2)) that contain information calculated during the L2A reflectance retrieval. These may be used as additional screening, depending on the application.\n",
    "\n",
    "> Note: It is more memory efficient to apply the mask before orthorectifying, so during the automation section we will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_mask = emit_xarray(emit_qa_fp, ortho=True)\n",
    "emit_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the quality flags contained in the `mask_bands` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_mask.mask_bands.data.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, we will use the `Dilated Cloud Flag`. Select that band with the `sel` function as we did for wavelengths before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_cloud_mask = emit_mask.sel(mask_bands='Dilated Cloud Flag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize our aggregate quality mask. You may have noticed before that we added a lot of parameters to our plotting function. If we want to consistently apply the same formatting for multiple plots, we can add those arguments to a dictionary that we can unpack into `hvplot` functions using `**`.\n",
    "\n",
    "Create two dictionaries with plotting options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size_opts = dict(frame_height=405, frame_width=720, fontscale=2)\n",
    "map_opts = dict(geo=True, crs='EPSG:4326', alpha=0.7, xlabel='Longitude',ylabel='Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_cloud_mask.hvplot.image(cmap='viridis', tiles='ESRI', **size_opts, **map_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values of 1 in the mask indicate areas to omit. Apply the mask to our EMIT Data by assigning values where the `mask.data == 1` to `np.nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_ds.reflectance.data[emit_cloud_mask.mask.data == 1] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm our masking worked with a spatial plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_layer_filtered_plot = emit_ds.sel(wavelengths=850, method='nearest').hvplot.image(cmap='viridis',tiles='ESRI',**size_opts, **map_opts)\n",
    "emit_layer_filtered_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Interactive Spectral Plots\n",
    "\n",
    "Combining the Spatial and Spectral information into a single visualization can be a powerful tool for exploring and inspecting imaging spectroscopy data. Using the streams module from Holoviews we can link a spatial map to a plot of spectra.\n",
    "\n",
    "We could plot a single band image as we previously have, but using a multiband image, like an RGB may help infer what targets we're examining. Build an RGB image following the steps below.\n",
    "\n",
    "Select bands to represent red (650 nm), green (560 nm), and blue (470 nm) by finding the nearest to a wavelength chosen to represent that color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_rgb = emit_ds.sel(wavelengths=[650, 560, 470], method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may need to adjust balance the brightness of the selected wavelengths to make a prettier map. **This will not affect the data, just the visuals.** To do this we will use the function below. We can change the `bright` argument to increase or decrease the brightness of the scene as a whole. A value of 0.2 usually works pretty well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gamma_adjust(rgb_ds, bright=0.2, white_background=False):\n",
    "    array = rgb_ds.reflectance.data\n",
    "    gamma = math.log(bright)/math.log(np.nanmean(array)) # Create exponent for gamma scaling - can be adjusted by changing 0.2 \n",
    "    scaled = np.power(np.nan_to_num(array,nan=1),np.nan_to_num(gamma,nan=1)).clip(0,1) # Apply scaling and clip to 0-1 range\n",
    "    if white_background == True:\n",
    "        scaled = np.nan_to_num(scaled, nan = 1) # Assign NA's to 1 so they appear white in plots\n",
    "    rgb_ds.reflectance.data = scaled\n",
    "    return rgb_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_rgb = gamma_adjust(emit_rgb,white_background=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an RGB dataset, we can use that to create a spatial plot, and data selected by clicking on that 'map' can be inputs for a function to return values from the full dataset at that latitude and longitude location using the cell below. To visualize the spectral and spatial data side-by-side, we use the Point Draw tool from the holoviews library.\n",
    "\n",
    "Define a limit to the quantity of points and spectra we will plot, a list of colors to cycle through, and an initial point. Then use the input from the Tap function to provide clicked x and y positions on the map and use these to retrieve spectra from the dataset at those coordinates.\n",
    "\n",
    "Click in the RGB image to add spectra to the plot. You can also click and hold the mouse button then drag previously placed points. To remove a point click and hold the mouse button down, then press the backspace key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Interactive Points Plotting\n",
    "# Modified from https://github.com/auspatious/hyperspectral-notebooks/blob/main/03_EMIT_Interactive_Points.ipynb\n",
    "POINT_LIMIT = 10\n",
    "color_cycle = hv.Cycle('Category20')\n",
    "\n",
    "# Create RGB Map\n",
    "map = emit_rgb.hvplot.rgb(fontscale=1.5, xlabel='Longitude',ylabel='Latitude',frame_width=480, frame_height=480)\n",
    "\n",
    "# Set up a holoviews points array to enable plotting of the clicked points\n",
    "xmid = emit_ds.longitude.values[int(len(emit_ds.longitude) / 2)]\n",
    "ymid = emit_ds.latitude.values[int(len(emit_ds.latitude) / 2)]\n",
    "\n",
    "first_point = ([xmid], [ymid], [0])\n",
    "points = hv.Points(first_point, vdims='id')\n",
    "points_stream = hv.streams.PointDraw(\n",
    "    data=points.columns(),\n",
    "    source=points,\n",
    "    drag=True,\n",
    "    num_objects=POINT_LIMIT,\n",
    "    styles={'fill_color': color_cycle.values[1:POINT_LIMIT+1], 'line_color': 'gray'}\n",
    ")\n",
    "\n",
    "posxy = hv.streams.PointerXY(source=map, x=xmid, y=ymid)\n",
    "clickxy = hv.streams.Tap(source=map, x=xmid, y=ymid)\n",
    "\n",
    "# Function to build spectral plot of clicked location to show on hover stream plot\n",
    "def click_spectra(data):\n",
    "    coordinates = []\n",
    "    if data is None or not any(len(d) for d in data.values()):\n",
    "        coordinates.append(clicked_points[0][0], clicked_points[1][0])\n",
    "    else:\n",
    "        coordinates = [c for c in zip(data['x'], data['y'])]\n",
    "    \n",
    "    plots = []\n",
    "    for i, coords in enumerate(coordinates):\n",
    "        x, y = coords\n",
    "        data = emit_ds.sel(longitude=x, latitude=y, method=\"nearest\")\n",
    "        plots.append(\n",
    "            data.hvplot.line(\n",
    "                y=\"reflectance\",\n",
    "                x=\"wavelengths\",\n",
    "                color=color_cycle,\n",
    "                label=f\"{i}\"\n",
    "            )\n",
    "        )\n",
    "        points_stream.data[\"id\"][i] = i\n",
    "    return hv.Overlay(plots)\n",
    "\n",
    "def hover_spectra(x,y):\n",
    "    return emit_ds.sel(longitude=x,latitude=y,method='nearest').hvplot.line(y='reflectance',x='wavelengths',\n",
    "                                                                            color='black', frame_width=400)\n",
    "# Define the Dynamic Maps\n",
    "click_dmap = hv.DynamicMap(click_spectra, streams=[points_stream])\n",
    "hover_dmap = hv.DynamicMap(hover_spectra, streams=[posxy])\n",
    "# Plot the Map and Dynamic Map side by side\n",
    "hv.Layout(hover_dmap*click_dmap + map * points).cols(2).opts(\n",
    "    hv.opts.Points(active_tools=['point_draw'], size=10, tools=['hover'], color='white', line_color='gray'),\n",
    "    hv.opts.Overlay(show_legend=False, show_title=False, fontscale=1.5, frame_height=480)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take these selected points and the corresponding reflectance spectra and save them as a `.csv` for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 10 points by adding to the figure above. We will save these and use them in a to calculate Equivalent Water Thickness or Canopy water content in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dictionary of the selected points and spectra, then export the spectra to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = points_stream.data\n",
    "wavelengths = emit_ds.wavelengths.values\n",
    "\n",
    "rows = [[\"id\", \"x\", \"y\"] + [str(i) for i in wavelengths]]\n",
    " \n",
    "for p in zip(data['x'], data['y'], data['id']):\n",
    "    x, y, i = p\n",
    "    spectra = emit_ds.sel(longitude=x, latitude=y, method=\"nearest\").reflectance.values\n",
    "    row = [i, x, y] + list(spectra)\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've preselected 10 points, but feel free to uncomment the cell below to use your own. This will overwrite the file containing the preselected points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('../data/emit_click_data.csv', 'w', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping EMIT data to a Region of Interest\n",
    "\n",
    "To crop our dataset to our bounding box, we first need to create a rectangular polygon from a given bounding box defined by geographic coordinates (longitude and latitude), and then wraps it in a GeoDataFrame. To ensure the plotting of the shape and EMIT scene works, be sure to specify the CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = Polygon([\n",
    "    (bbox[0], bbox[1]),  # bottom-left\n",
    "    (bbox[0], bbox[3]),  # top-left\n",
    "    (bbox[2], bbox[3]),  # top-right\n",
    "    (bbox[2], bbox[1]),  # bottom-right\n",
    "    (bbox[0], bbox[1])   # close the polygon\n",
    "])\n",
    "\n",
    "# Create a GeoDataFrame with the polygon\n",
    "shape = gp.GeoDataFrame({'geometry': [polygon]}, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_ds.sel(wavelengths=850, method='nearest').hvplot.image(cmap='viridis',**size_opts,**map_opts,tiles='ESRI')*shape.hvplot(color='#d95f02',alpha=0.5, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `clip` function from `rasterio` to crop the data to our ROI using our shape's `geometry` and `crs`. The `all_touched=True` argument will ensure all pixels touched by our polygon will be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_cropped = emit_ds.rio.clip(shape.geometry.values,shape.crs, all_touched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the cropped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_cropped.sel(wavelengths=850,method='nearest').hvplot.image(cmap='viridis', tiles='ESRI', **size_opts, **map_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write an output\n",
    "\n",
    "Lastly for our EMIT dataset, we can write a smaller output that we can use in later notebooks, to calculate Canopy water content or other applications. We use the `granule_id` from the dataset to keep a similar naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write Clipped Output\n",
    "emit_cropped.to_netcdf(f'../data/{emit_cropped.granule_id}_dangermond.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
